# Smart Order Router (SOR) Backtesting System Architecture

A modular system for backtesting and simulating real-time market data using Kafka, implementing the Cont & Kukanov allocation model, and benchmarking against standard execution strategies.

---

## ğŸ“ File & Folder Structure

```
.
â”œâ”€â”€ allocator.py            # Implements static Cont-Kukanov allocation logic
â”œâ”€â”€ backtest.py             # Orchestrates parameter tuning, benchmarking, and result evaluation
â”œâ”€â”€ kafka_producer.py       # Streams market snapshots from l1_day.csv into Kafka
â”œâ”€â”€ config.py               # Global constants and parameters
â”œâ”€â”€ utils.py                # Common helper functions (e.g., time deltas, JSON formatting)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # Project overview, CLI commands, and EC2 deployment instructions
â”œâ”€â”€ allocator_pseudocode.txt# Reference pseudocode for static Cont-Kukanov allocator
â”œâ”€â”€ results.png             # Optional performance comparison plot
â””â”€â”€ output.json             # Optional final JSON result dump
```

---

## ğŸ”„ Data Flow & Service Connections

```text
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ l1_day.csv â”‚   â† Market snapshot data (ask, size, fee, rebate)
            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ kafka_producer.py  â”‚  â† Reads CSV and streams JSON snapshots to Kafka
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
        Kafka Topic: `mock_l1_stream`
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   backtest.py      â”‚  â† Consumes snapshots, runs allocator, computes baselines
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  allocator.py      â”‚  â† Computes optimal split per snapshot using static CK model
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  output.json       â”‚  â† Stores final performance summary as JSON
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Component Responsibilities

* **allocator.py**

  * Implements the static Cont-Kukanov allocation algorithm.
  * Brute-force search in 100-share increments.
  * Cost model includes execution cost, under/overfill penalties, and queue-risk penalty.

* **kafka\_producer.py**

  * Parses `l1_day.csv`.
  * Formats each row into a JSON snapshot with fields: `timestamp`, `venue`, `ask_px_00`, `ask_sz_00`, `fee`, `rebate`.
  * Streams snapshots to topic `mock_l1_stream` using `kafka-python`.
  * Simulates real-time pacing via `time.sleep()` based on `ts_event` deltas.

* **backtest.py**

  * Subscribes to Kafka topic.
  * Groups snapshots by timestamp and passes venue data to allocator.
  * Runs parameter grid search on `(lambda_over, lambda_under, theta_queue)`.
  * Executes baseline strategies: Best Ask, TWAP (60s), and VWAP.
  * Calculates metrics: total cash, average fill price, savings in bps.
  * Outputs final JSON and (optionally) generates `results.png`.

* **config.py**

  * Centralizes constants: Kafka settings, order size (5,000), time window, parameter grids, CSV path.

* **utils.py**

  * Helper functions for parsing time, formatting JSON, computing VWAP/TWAP weights.

---

## ğŸš€ Deployment Outline (for README)

1. **EC2 Instance**

   * Type: `t3.micro` or `t4g.micro`.
2. **Kafka & Zookeeper Setup**

   * Install Java, Kafka, and Zookeeper via `apt` or `yum`.
   * Configure systemd services.
3. **Python Environment**

   * `python3.8+` virtual environment.
   * `pip install -r requirements.txt`.
4. **Running the Pipeline**

   * Start Zookeeper & Kafka.
   * Run `python kafka_producer.py`.
   * In parallel, run `python backtest.py`.
5. **Verification Screenshots**

   * Kafka console consumer showing messages.
   * Backtest stdout JSON.
   * `uname -a` / `uptime` for system info.
